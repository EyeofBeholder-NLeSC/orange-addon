{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I always get a half size up in my tennis shoes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Put them on and walked 3 hours with no problem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>excelente</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The shoes fit well in the arch area. They are ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tried them on in a store before buying online ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>Favorite Nike shoe ever! The flex sole is exce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>I wear these everyday to work, the gym, etc.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>Love these shoes! Great fit, very light weight.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>Super comfortable and fit my small feet perfec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>Love these shoes!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>369 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            reviewText\n",
       "0    I always get a half size up in my tennis shoes...\n",
       "1    Put them on and walked 3 hours with no problem...\n",
       "2                                            excelente\n",
       "3    The shoes fit well in the arch area. They are ...\n",
       "4    Tried them on in a store before buying online ...\n",
       "..                                                 ...\n",
       "364  Favorite Nike shoe ever! The flex sole is exce...\n",
       "365       I wear these everyday to work, the gym, etc.\n",
       "366    Love these shoes! Great fit, very light weight.\n",
       "367  Super comfortable and fit my small feet perfec...\n",
       "368                                  Love these shoes!\n",
       "\n",
       "[369 rows x 1 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dpath = '../data/sample_input.json'\n",
    "\n",
    "df = pd.read_json(dpath, lines=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I always get a half size up in my tennis shoes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Put them on and walked 3 hours with no problem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>excelente</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The shoes fit well in the arch area. They are ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tried them on in a store before buying online ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>Favorite Nike shoe ever! The flex sole is exce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>I wear these everyday to work, the gym, etc.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>Love these shoes! Great fit, very light weight.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>Super comfortable and fit my small feet perfec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>Love these shoes!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>369 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            reviewText\n",
       "0    I always get a half size up in my tennis shoes...\n",
       "1    Put them on and walked 3 hours with no problem...\n",
       "2                                            excelente\n",
       "3    The shoes fit well in the arch area. They are ...\n",
       "4    Tried them on in a store before buying online ...\n",
       "..                                                 ...\n",
       "364  Favorite Nike shoe ever! The flex sole is exce...\n",
       "365       I wear these everyday to work, the gym, etc.\n",
       "366    Love these shoes! Great fit, very light weight.\n",
       "367  Super comfortable and fit my small feet perfec...\n",
       "368                                  Love these shoes!\n",
       "\n",
       "[369 rows x 1 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reviews = df.loc[df.astype('str').drop_duplicates().index]\n",
    "df_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.readability(doc)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "import pytextrank\n",
    "from spacy.language import Language\n",
    "from spacy_readability import Readability\n",
    "from importlib.util import find_spec\n",
    "\n",
    "@Language.component(\"readability\")\n",
    "def readability(doc):\n",
    "    read = Readability()\n",
    "    doc = read(doc)\n",
    "    return doc\n",
    "\n",
    "pipe_name = 'en_core_web_md'\n",
    "\n",
    "if find_spec(pipe_name) is None:\n",
    "    spacy.cli.download(pipe_name)\n",
    "\n",
    "nlp = spacy.load(pipe_name)\n",
    "nlp.add_pipe(\"textrank\", last=True)\n",
    "nlp.add_pipe(\"readability\", last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_ranking(doc, trt):\n",
    "    results = []\n",
    "    for phrase in doc._.phrases:\n",
    "        if phrase.rank >= trt:\n",
    "            results.append((phrase.text, phrase.rank))\n",
    "    return results\n",
    "\n",
    "def apply_readability(doc):\n",
    "    return doc._.flesch_kincaid_reading_ease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: 369\n",
      "Sample: [[('my tennis shoes', 0.12971597081854963), ('the heel area', 0.11278192619619307), ('a half', 0.053635551595810474), ('some reason', 0.04734609155372741), ('I', 0.0), ('these', 0.0)], 92.43000000000002]\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "docs = nlp.pipe(texts=df_reviews['reviewText'].astype('str'))\n",
    "for doc in docs:\n",
    "    scores.append([apply_ranking(doc, 0), apply_readability(doc)])\n",
    "print('Size:', len(scores))\n",
    "print('Sample:', scores[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>ranks</th>\n",
       "      <th>n_tokens</th>\n",
       "      <th>readability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>Favorite training and walking-around sneakers....</td>\n",
       "      <td>[(gym use, 0.09606191299609641), (flex supreme...</td>\n",
       "      <td>52</td>\n",
       "      <td>70.526224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>I am a recess aide and on my feet all day long...</td>\n",
       "      <td>[(hip pain, 0.13045310873361876), (time, 0.111...</td>\n",
       "      <td>43</td>\n",
       "      <td>87.037802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>I LOVE the look and comfort of these shoes for...</td>\n",
       "      <td>[(major back issues, 0.16276363627717572), (ot...</td>\n",
       "      <td>37</td>\n",
       "      <td>90.683676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>Super light-weight, decent arch support (mine ...</td>\n",
       "      <td>[(Shoes, 0.15014668465326747), (shoe, 0.150146...</td>\n",
       "      <td>35</td>\n",
       "      <td>65.562910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Very good overall.\\nNow Ive been a huge Sketch...</td>\n",
       "      <td>[(Walt Disney World, 0.12001095576359547), (So...</td>\n",
       "      <td>35</td>\n",
       "      <td>78.244199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>Cute and comfortable</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>34.590000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>Very comfortable.</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>-48.995000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>Super comfy!</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>35.605000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>Nice looking and fit nice</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>100.240000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>Really comfortable and very cute.</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>15.640000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>369 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            reviewText  \\\n",
       "313  Favorite training and walking-around sneakers....   \n",
       "347  I am a recess aide and on my feet all day long...   \n",
       "318  I LOVE the look and comfort of these shoes for...   \n",
       "64   Super light-weight, decent arch support (mine ...   \n",
       "57   Very good overall.\\nNow Ive been a huge Sketch...   \n",
       "..                                                 ...   \n",
       "249                               Cute and comfortable   \n",
       "198                                  Very comfortable.   \n",
       "101                                       Super comfy!   \n",
       "346                          Nice looking and fit nice   \n",
       "290                  Really comfortable and very cute.   \n",
       "\n",
       "                                                 ranks  n_tokens  readability  \n",
       "313  [(gym use, 0.09606191299609641), (flex supreme...        52    70.526224  \n",
       "347  [(hip pain, 0.13045310873361876), (time, 0.111...        43    87.037802  \n",
       "318  [(major back issues, 0.16276363627717572), (ot...        37    90.683676  \n",
       "64   [(Shoes, 0.15014668465326747), (shoe, 0.150146...        35    65.562910  \n",
       "57   [(Walt Disney World, 0.12001095576359547), (So...        35    78.244199  \n",
       "..                                                 ...       ...          ...  \n",
       "249                                                 []         0    34.590000  \n",
       "198                                                 []         0   -48.995000  \n",
       "101                                                 []         0    35.605000  \n",
       "346                                                 []         0   100.240000  \n",
       "290                                                 []         0    15.640000  \n",
       "\n",
       "[369 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reviews['ranks'] = [p[0] for p in scores]\n",
    "df_reviews['n_tokens'] = [len(p[0]) for p in scores]\n",
    "df_reviews['readability'] = [p[1] for p in scores]\n",
    "df_reviews.sort_values(by='n_tokens', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "\n",
    "stopwords = list(nlp.Defaults.stop_words)\n",
    "\n",
    "model_name = 'word2vec-google-news-300' \n",
    "\n",
    "# HACK: Temporary fix -@jiqi at 11/18/2022, 10:23:14 AM\n",
    "# This line checks if the model file is ready and then load it.\n",
    "# Should check why it takes so long (~32 secs)\n",
    "model = api.load(model_name) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1580"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = []\n",
    "for phrases_rank in list(df_reviews['ranks']):\n",
    "    for phrase in phrases_rank:\n",
    "        phrase = phrase[0].lower().split()\n",
    "        phrase = filter(lambda t: t not in stopwords, phrase)\n",
    "        phrase = ' '.join(phrase)\n",
    "        if phrase: tokens.append(phrase.split(' '))\n",
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['tennis', 'shoes'], ['heel', 'area'])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import starmap, combinations\n",
    "\n",
    "combis = list(combinations(tokens, 2))\n",
    "combis[0]\n",
    "# dists = np.array(list(starmap(model.wmdistance, combis)))\n",
    "# dists = np.nan_to_num(dists, nan=0, posinf=100)\n",
    "# dists[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool, cpu_count\n",
    "from joblib import Parallel, delayed\n",
    "from functools import partial\n",
    "from itertools import starmap\n",
    "\n",
    "# FIXME: seems not correct to pass strings as input, but should be list of strings (words)\n",
    "# In the souce code of wmdistance function, it checks if the words in the input documents\n",
    "# are there in the keyedvector model. If not, a inf distance will be given to that pair.\n",
    "# But if the input is document as string but not a list of words included, it will always\n",
    "# calculate the distance by English charactors, which will always return a value in [0, 1l]\n",
    "dists = list(starmap(model.wmdistance, combis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = np.zeros((len(tokens), len(tokens)))\n",
    "# data[np.triu_indices(len(tokens), 1)] = dists\n",
    "# data = data + data.T\n",
    "# df_matrix = pd.DataFrame(data, index=tokens, columns=tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Exploration on speeding up the process of computing pair-wise wmdistances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple for-loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple for loop performs similarly as itertools.starmap\n",
    "dists_for = [model.wmdistance(c[0], c[1]) for c in combis]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from multiprocessing import Pool, cpu_count\n",
    "from functools import partial\n",
    "\n",
    "def calc_wmdistance(model, doc1, doc2):\n",
    "    return model.wmdistance(doc1, doc2)\n",
    "\n",
    "job = partial(calc_wmdistance, model)\n",
    "\n",
    "with Pool(processes=cpu_count()) as pool:\n",
    "    # # async function\n",
    "    # result = pool.starmap_async(job, combis)\n",
    "    # data = result.get()\n",
    "\n",
    "    # sync function\n",
    "    # data = pool.starmap(job, combis, chunksize=10)\n",
    "    data = pool.starmap(job, combis)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### joblib\n",
    "\n",
    "It's hard to get the desired speedup by directly applying mp or joblib to the static version of the function, as the model is likely quite large and pickle-sending it to the child processes for each calculation dominates the runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "\n",
    "\n",
    "# can't use the instance_bound function directly here, so use the static version instead\n",
    "result = Parallel(n_jobs=-2)(calc_wmdistance(model, combi) for combi in combis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rewrite the wmdistance function as static\n",
    "\n",
    "To solve the pickle-sending issue above, a possible solution is to have the model (actually only a very large array is needed) defined globally and stored in a shared memory so that the child processes can get access to them directly.\n",
    "\n",
    "However, this also doesn't work. The kernel even crashed before finishing computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# static version of the wmdistance function, with shared memory of storing the\n",
    "# word index and vectors generated by the gensim model. \n",
    "\n",
    "from pyemd import emd\n",
    "from multiprocessing import Manager, RawArray\n",
    "import numpy as np\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "# shared memory that stored the token index and vectors\n",
    "TOKEN_INDEX = Manager().list(model.index_to_key)\n",
    "v_shape = model.vectors.shape\n",
    "vectors = RawArray('f', v_shape[0] * v_shape[1])\n",
    "TOKEN_VECTORS = np.frombuffer(vectors, dtype=np.float32).reshape(v_shape)\n",
    "np.copyto(TOKEN_VECTORS, model.vectors)\n",
    "\n",
    "\n",
    "def init_pool(shared_t_index, shared_t_vectors):\n",
    "    global t_index, t_vectors\n",
    "    t_index = shared_t_index\n",
    "    t_vectors = shared_t_vectors\n",
    "\n",
    "def calc_wmdistance(doc1, doc2):\n",
    "    doc1 = [w for w in doc1 if w in t_index]\n",
    "    doc2 = [w for w in doc2 if w in t_index]\n",
    "\n",
    "    # if any of the input is empty, return inf\n",
    "    if not doc1 or not doc2: return float('inf')\n",
    "\n",
    "    dictionary = Dictionary(documents=[doc1, doc2])\n",
    "    vocab_len = len(dictionary)\n",
    "\n",
    "    # if both input docs contain the same unique token, return 0\n",
    "    if vocab_len == 1: return 0.0\n",
    "\n",
    "    doclist1 = list(set(doc1))\n",
    "    doclist2 = list(set(doc2))\n",
    "\n",
    "    # get list of word vectors for each document\n",
    "    v1 = []\n",
    "    for w in doclist1:\n",
    "        i = t_index.index(w)\n",
    "        v = t_vectors[i]\n",
    "        v = v / np.linalg.norm(v)\n",
    "        v1.append(v)\n",
    "    v1 = np.array(v1)\n",
    "    v2 = []\n",
    "    for w in doclist2:\n",
    "        i = t_index.index(w)\n",
    "        v = t_vectors[i]\n",
    "        v = v / np.linalg.norm(v)\n",
    "        v2.append(v)\n",
    "    v2 = np.array(v2)\n",
    "\n",
    "    # compute distance matrix\n",
    "    doc1_indices = dictionary.doc2idx(doclist1)\n",
    "    doc2_indices = dictionary.doc2idx(doclist2)\n",
    "    distance_matrix = np.zeros((vocab_len, vocab_len), dtype=np.double)\n",
    "    distance_matrix[np.ix_(doc1_indices, doc2_indices)] = cdist(v1, v2)\n",
    "\n",
    "    # if distance matrix is all zero, return inf\n",
    "    if abs(np.sum(distance_matrix)) < 1e-8: return float('inf')\n",
    "\n",
    "    d1 = np.zeros(vocab_len, dtype=np.double)\n",
    "    d2 = np.zeros(vocab_len, dtype=np.double)\n",
    "    doc1_len = len(doc1)\n",
    "    doc2_len = len(doc2)\n",
    "    for i, f in dictionary.doc2bow(doc1):\n",
    "        d1[i] = f / float(doc1_len)\n",
    "    for i, f in dictionary.doc2bow(doc2):\n",
    "        d2[i] = f / float(doc2_len) \n",
    "    \n",
    "    return emd(d1, d2, distance_matrix)\n",
    "\n",
    "# # test if the output is the same as the original function\n",
    "# doc1 = tokens[0]\n",
    "# doc2 = tokens[1]\n",
    "# calc_wmdistance(doc1, doc2) == model.wmdistance(doc1.split(' '), doc2.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool, cpu_count\n",
    "\n",
    "with Pool(processes=cpu_count() - 1, initializer=init_pool, initargs=(TOKEN_INDEX, TOKEN_VECTORS, )) as pool:\n",
    "    data = pool.starmap_async(calc_wmdistance, combis, chunksize=10)\n",
    "    result = data.get()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('orange')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "006dad53e7afa06f8028c9480631d8321d543ccd52a45f3ccb542c0a0c4ce76e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
